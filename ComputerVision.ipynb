{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e993fb1e-c558-4f7a-a6b6-93aa33d0c530",
   "metadata": {},
   "source": [
    "## Python for Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df1bee-6447-40c1-938a-e4f711a9214d",
   "metadata": {},
   "source": [
    "### Description\n",
    "This project demonstrates MNIST digit classification using a MLP neural network. The process includes Data preprocessing, hyperparameter tuning using RandomsSearch, model building using the cusom build_deep_nn function, and optimal model evaluation on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c410f2-f340-408e-bbb6-7a8bc44e3288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 13:22:23.793807: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5t/0bxhn3f90pv92yp3ffchl8pr0000gn/T/ipykernel_9757/433827705.py:11: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n",
    "import a1\n",
    "from kerastuner.tuners import RandomSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30240081-d985-4089-94f0-b6e75f1cc9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading MNIST training and test datasets.\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c43620-9c4a-420b-9783-6a09209b81f0",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "* Here,the pixel values originally represented as integers are normalised scales between the range of 0-1 to help with training and testing the model. <br>\n",
    "* Further, we have One-Hot Encoded the label values transforing thm from integer to binary vectors, where each vector has a length equal to the number of classes (10). It helps the nueral network in understanding the categorical nature of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd12aaeb-9faa-43d0-bd19-267359b9b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalizing pixel values in the range [0, 1] for both training and test images.\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "train_labels = to_categorical(train_labels, num_classes = 10)\n",
    "test_labels = to_categorical(test_labels,num_classes =10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21023b64-1e15-4884-bdc4-fb25644873e1",
   "metadata": {},
   "source": [
    "### Hyperparameter Search Space and Model Building Function\n",
    "### build_model function\n",
    "* The build_model function helps in defining a search space for hyperparameters using Keras Tuner's HyperParameters (hp) object.\n",
    "* Hyperparameters include the number of hidden layers, the size of each hidden layer, and the dropout rate for regularization, the details for which are already provided.\n",
    "* This function builds a neural network using a1.build_deep_nn with architecture parameters determined by the hyperparameters.\n",
    "### Compiling\n",
    "* This model is then compiled using Adam optimizer, categorical crossentropy loss and accuracy.\n",
    "### Hyperparameter tuning using RandomSearch\n",
    "* A RandomSearch tuner is initialized with the build_model function as the target, aiming to maximize validation accuracy.\n",
    "* The search is conducted over a predefined number of trials (max_trials) with multiple executions per trial (executions_per_trial).\n",
    "* The search is performed using the training data with a validation split, and the results are stored in the 'keras_tuner_logs' directory.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ae8e05-3647-40f2-8246-2c91bd9b4c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 19s]\n",
      "val_accuracy: 0.9710833311080933\n",
      "\n",
      "Best val_accuracy So Far: 0.9745583355426788\n",
      "Total elapsed time: 00h 43m 46s\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    # Defining hyperparameters\n",
    "    rows, columns, channels = 28, 28, 1  # MNIST image dimensions\n",
    "\n",
    "    # Number of hidden layers\n",
    "    num_hidden_layers = hp.Int('num_hidden_layers', 1, 3)\n",
    "\n",
    "    # Size of hidden layers\n",
    "    hidden_size = hp.Int('hidden_size', 32, 128, step=32)\n",
    "\n",
    "    # Dropout rate of the final hidden layer\n",
    "    dropout_rate = hp.Float('dropout_rate', 0, 0.5, step=0.1)\n",
    "\n",
    "    # Output size and activation\n",
    "    output_size = 10\n",
    "    output_activation = 'softmax'\n",
    "\n",
    "    # building neural network using build_deep_nn\n",
    "    model = a1.build_deep_nn(rows, columns, channels, num_hidden_layers, [hidden_size] * num_hidden_layers,\n",
    "                           [0] * (num_hidden_layers - 1) + [dropout_rate], output_size, output_activation)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "    \n",
    "# Initializing the RandomSearch tuner for hyperparamater optimization\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    executions_per_trial = 10,\n",
    "    max_trials=5,  # You can adjust this value based on computational resources\n",
    "    directory='keras_tuner_logs',\n",
    "    project_name='mnist_tuning'\n",
    ")\n",
    "# Searching for the optimal hyperparameters using the training data with validation split\n",
    "tuner.search(train_images, train_labels, epochs=5, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e057d9-5e38-47d4-a7f3-503e043c0e03",
   "metadata": {},
   "source": [
    "## Optimal Model\n",
    "* The best hyperparameters are obtained from the tuner search are then extracted and a new model is built with them.\n",
    "* The model is then trained for a specified number of epoch with a validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09f3360b-6e9d-419a-8720-7f5c768e0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the best hyperparameters from the search\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# using the best hyperparamaters to build a model\n",
    "optimal_model = build_model(best_hps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bfeb8ac-ba00-4c0e-b6d8-dc295bbbdc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 3s 1ms/step - loss: 0.2920 - accuracy: 0.9129 - val_loss: 0.1371 - val_accuracy: 0.9578\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1249 - accuracy: 0.9618 - val_loss: 0.0992 - val_accuracy: 0.9708\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0854 - accuracy: 0.9736 - val_loss: 0.0857 - val_accuracy: 0.9743\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0675 - accuracy: 0.9796 - val_loss: 0.0839 - val_accuracy: 0.9748\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0560 - accuracy: 0.9823 - val_loss: 0.0871 - val_accuracy: 0.9754\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0456 - accuracy: 0.9850 - val_loss: 0.0951 - val_accuracy: 0.9732\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0343 - accuracy: 0.9889 - val_loss: 0.0891 - val_accuracy: 0.9775\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0314 - accuracy: 0.9893 - val_loss: 0.0953 - val_accuracy: 0.9763\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0274 - accuracy: 0.9913 - val_loss: 0.0969 - val_accuracy: 0.9772\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0242 - accuracy: 0.9920 - val_loss: 0.0915 - val_accuracy: 0.9799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f95f245ba30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model on training data\n",
    "optimal_model.fit(train_images, train_labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e35437a-11d5-4113-a766-ff14482a7b09",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "* This trained model is then evaluated on a test dataset, and then test loss and accuracy are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e7379e0-ebc5-45d8-9a30-1044116f3f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 642us/step - loss: 0.0983 - accuracy: 0.9770\n",
      "Test Accuracy: 0.9769999980926514\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model on the test dataset\n",
    "test_loss, test_accuracy = optimal_model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455dbc2f-1072-46f7-9263-1b720332dba2",
   "metadata": {},
   "source": [
    "### What are the hyperparameters of the optimal model?\n",
    "Best Hyperparameters: <br>\n",
    "Number of Hidden Layers: 2 <br>\n",
    "Hidden Layer Size: 128 <br>\n",
    "Dropout Rate: 0.2 <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5e550e-d2c5-4677-a90e-e5b4303d5b08",
   "metadata": {},
   "source": [
    "### What are the accuracy results of the optimal model on the test set?\n",
    "Test Accuracy: 0.9769999980926514 or 97.7%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
